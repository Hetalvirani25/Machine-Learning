{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8adddf19",
      "metadata": {
        "id": "8adddf19"
      },
      "source": [
        "# Lab1 - Scikit-learn\n",
        "Author: *YOUR NAME*\n",
        "\n",
        "#### Due Date: Sunday, February 12 at 11:59pm\n",
        "\n",
        "#### To submit: Google Colab link for the completed code file\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "The goal of this lab is to become more familiar with the scikit-learn library\n",
        "\n",
        "You will practice loading example datasets, perform classification and regression with linear scikit-learn models, and investigate the effects of reducing the number of features (columns in X) and the number of samples (rows in X and y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "567659e0",
      "metadata": {
        "id": "567659e0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mglearn\n",
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlTUZQKQO4Ly",
        "outputId": "5ca2b608-6f6a-488f-ede1-66ce4024b217"
      },
      "id": "KlTUZQKQO4Ly",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mglearn\n",
            "  Downloading mglearn-0.1.9.tar.gz (540 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mglearn) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mglearn) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from mglearn) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from mglearn) (1.3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from mglearn) (7.1.2)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.8/dist-packages (from mglearn) (0.11.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from mglearn) (2.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from mglearn) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mglearn) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mglearn) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mglearn) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->mglearn) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->mglearn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->mglearn) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->mglearn) (1.15.0)\n",
            "Building wheels for collected packages: mglearn\n",
            "  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582637 sha256=ef77adce1398b8eb5778f1933bce0f1e07062f87050c7cf01c6360756d9e2246\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/75/37/404e66d0c4bad150f101c9a0914b11a8eccc2681559936e7f7\n",
            "Successfully built mglearn\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.1.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import utils"
      ],
      "metadata": {
        "id": "JlnDPnMIPXhv"
      },
      "id": "JlnDPnMIPXhv",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade joblib==1.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlsiclE7knnl",
        "outputId": "b0a77222-6ec3-43d9-cf8f-511a19201f6a"
      },
      "id": "BlsiclE7knnl",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting joblib==1.1.0\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: joblib\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.2.0\n",
            "    Uninstalling joblib-1.2.0:\n",
            "      Successfully uninstalled joblib-1.2.0\n",
            "Successfully installed joblib-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mglearn"
      ],
      "metadata": {
        "id": "qUfY5PVZkwQS"
      },
      "id": "qUfY5PVZkwQS",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mglearn.plots.plot_linear_regression_wave()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "PouO6fuek06y",
        "outputId": "0f03de6b-fba3-4e52-fc9a-55682ac2e191"
      },
      "id": "PouO6fuek06y",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w[0]: 0.393906  b: -0.031804\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') "
      ],
      "metadata": {
        "id": "h6NeA5QHk8WD"
      },
      "id": "h6NeA5QHk8WD",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "33905120",
      "metadata": {
        "id": "33905120"
      },
      "source": [
        "## 2. Classification (15 marks total)\n",
        "\n",
        "Using spam dataset - classification  \n",
        "https://archive.ics.uci.edu/ml/datasets/spambase\n",
        "\n",
        "The goal is to investigate `LogisticRegression(max_iter=2000)` and the effects of reducing the number of features and number of samples on classification performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3f7c65d",
      "metadata": {
        "id": "a3f7c65d"
      },
      "source": [
        "### 2.1 Load data (4 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66ae93da",
      "metadata": {
        "id": "66ae93da"
      },
      "source": [
        "#### First step: Check first few lines of data file using !head or !type\n",
        "\n",
        "Hint: Use this to check what the separator (sep) is and if column headers are included"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "45cd5721",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45cd5721",
        "outputId": "b260d211-a701-4708-a8e1-e42755368fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0,0.64,0.64,0,0.32,0,0,0,0,0,0,0.64,0,0,0,0.32,0,1.29,1.93,0,0.96,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.778,0,0,3.756,61,278,1\r\n",
            "0.21,0.28,0.5,0,0.14,0.28,0.21,0.07,0,0.94,0.21,0.79,0.65,0.21,0.14,0.14,0.07,0.28,3.47,0,1.59,0,0.43,0.43,0,0,0,0,0,0,0,0,0,0,0,0,0.07,0,0,0,0,0,0,0,0,0,0,0,0,0.132,0,0.372,0.18,0.048,5.114,101,1028,1\r\n",
            "0.06,0,0.71,0,1.23,0.19,0.19,0.12,0.64,0.25,0.38,0.45,0.12,0,1.75,0.06,0.06,1.03,1.36,0.32,0.51,0,1.16,0.06,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.06,0,0,0.12,0,0.06,0.06,0,0,0.01,0.143,0,0.276,0.184,0.01,9.821,485,2259,1\r\n",
            "0,0,0,0,0.63,0,0.31,0.63,0.31,0.63,0.31,0.31,0.31,0,0,0.31,0,0,3.18,0,0.31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.137,0,0.137,0,0,3.537,40,191,1\r\n",
            "0,0,0,0,0.63,0,0.31,0.63,0.31,0.63,0.31,0.31,0.31,0,0,0.31,0,0,3.18,0,0.31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.135,0,0.135,0,0,3.537,40,191,1\r\n",
            "0,0,0,0,1.85,0,0,1.85,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.223,0,0,0,0,3,15,54,1\r\n",
            "0,0,0,0,1.92,0,0,0,0,0.64,0.96,1.28,0,0,0,0.96,0,0.32,3.85,0,0.64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.054,0,0.164,0.054,0,1.671,4,112,1\r\n",
            "0,0,0,0,1.88,0,0,1.88,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.206,0,0,0,0,2.45,11,49,1\r\n",
            "0.15,0,0.46,0,0.61,0,0.3,0,0.92,0.76,0.76,0.92,0,0,0,0,0,0.15,1.23,3.53,2,0,0,0.15,0,0,0,0,0,0,0,0,0.15,0,0,0,0,0,0,0,0,0,0.3,0,0,0,0,0,0,0.271,0,0.181,0.203,0.022,9.744,445,1257,1\r\n",
            "0.06,0.12,0.77,0,0.19,0.32,0.38,0,0.06,0,0,0.64,0.25,0,0.12,0,0,0.12,1.67,0.06,0.71,0,0.19,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.06,0,0,0,0,0.04,0.03,0,0.244,0.081,0,1.729,43,749,1\r\n"
          ]
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE (0.5 marks)\n",
        "!head spambase.data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bef80f1",
      "metadata": {
        "id": "5bef80f1"
      },
      "source": [
        "#### Second step: Read in csv file\n",
        "\n",
        "Hint 1: From the previous step, what separator should be used?\n",
        "\n",
        "Hint 2: If there are no column headers, how does this change how we read in the data? \n",
        "\n",
        "Hint 3: If there are no column headers, do not need to define them - can index columns using numerical index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1b6870b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b6870b0",
        "outputId": "a697ccd4-face-4c31-9bc5-7d3afc5f7d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0     1     2    3     4     5     6     7     8     9   ...     48  \\\n",
            "0     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
            "1     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
            "2     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
            "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
            "4     0.00  0.00  0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.000   \n",
            "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
            "4595  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
            "4596  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
            "4597  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
            "4598  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
            "4599  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
            "\n",
            "         49   50     51     52     53     54   55    56  57  \n",
            "0     0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
            "1     0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
            "2     0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
            "3     0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
            "4     0.223  0.0  0.000  0.000  0.000  3.000   15    54   1  \n",
            "...     ...  ...    ...    ...    ...    ...  ...   ...  ..  \n",
            "4595  0.232  0.0  0.000  0.000  0.000  1.142    3    88   0  \n",
            "4596  0.000  0.0  0.353  0.000  0.000  1.555    4    14   0  \n",
            "4597  0.718  0.0  0.000  0.000  0.000  1.404    6   118   0  \n",
            "4598  0.057  0.0  0.000  0.000  0.000  1.147    5    78   0  \n",
            "4599  0.000  0.0  0.125  0.000  0.000  1.250    5    40   0  \n",
            "\n",
            "[4600 rows x 58 columns]\n"
          ]
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE (1 mark)\n",
        "data = pd.read_csv('spambase.data',na_values='?')\n",
        "df=pd.DataFrame(data)\n",
        "\n",
        "df.columns=[i for i in range(58)]\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fb17ee6",
      "metadata": {
        "id": "7fb17ee6"
      },
      "source": [
        "#### Third step: Find any null values and use a reasonable method to deal with them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "08768db6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08768db6",
        "outputId": "99c280ef-0cd5-4d33-fe12-cdca643a06af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    0\n",
              "15    0\n",
              "16    0\n",
              "17    0\n",
              "18    0\n",
              "19    0\n",
              "20    0\n",
              "21    0\n",
              "22    0\n",
              "23    0\n",
              "24    0\n",
              "25    0\n",
              "26    0\n",
              "27    0\n",
              "28    0\n",
              "29    0\n",
              "30    0\n",
              "31    0\n",
              "32    0\n",
              "33    0\n",
              "34    0\n",
              "35    0\n",
              "36    0\n",
              "37    0\n",
              "38    0\n",
              "39    0\n",
              "40    0\n",
              "41    0\n",
              "42    0\n",
              "43    0\n",
              "44    0\n",
              "45    0\n",
              "46    0\n",
              "47    0\n",
              "48    0\n",
              "49    0\n",
              "50    0\n",
              "51    0\n",
              "52    0\n",
              "53    0\n",
              "54    0\n",
              "55    0\n",
              "56    0\n",
              "57    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE (0.5 marks)\n",
        "df.dtypes\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24b9cfa0",
      "metadata": {
        "id": "24b9cfa0"
      },
      "source": [
        "#### Fourth step: Split dataset into feature matrix `X` and target vector `y`\n",
        "Print dimensions and type of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c613952a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c613952a",
        "outputId": "16901347-aa39-483b-d4cd-d9fc260e0f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X-dimension (4600, 49)\n",
            "y-dimension (4600, 9)\n"
          ]
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE (1 mark)\n",
        "\n",
        "X, y = df.iloc[:,0:49],df.iloc[:,49:59]\n",
        "print(\"X-dimension\",X.shape)\n",
        "# print(X.dtypes)\n",
        "# print('----------------------------------------------')\n",
        "# print('----------------------------------------------')\n",
        "print(\"y-dimension\",y.shape)\n",
        "# print(y.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2e185dc",
      "metadata": {
        "id": "e2e185dc"
      },
      "source": [
        "Using the sklearn function `train_test_split()` prepare an additional feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`\n",
        "\n",
        "Print dimensions and type of `X_small` and `y_small`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "874b3248",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874b3248",
        "outputId": "e8c2e2eb-df3b-4706-ac61-1e3d40b37852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X-small-dimension (46, 49)\n",
            "y_small-dimension (46, 9)\n"
          ]
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE (1 mark)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = df.iloc[:,0:49],df.iloc[:,49:59]\n",
        "X_train, X_small, y_train, y_small = train_test_split(X, y, test_size=0.01, random_state=174)\n",
        "\n",
        "print(\"X-small-dimension\",X_small.shape)\n",
        "# print(X_small.dtypes)\n",
        "print(\"y_small-dimension\",y_small.shape)\n",
        "# print(y_small.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5b229fb",
      "metadata": {
        "id": "f5b229fb"
      },
      "source": [
        "### 2.2 Implement accuracy function (3 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6688a036",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6688a036",
        "outputId": "aa320431-33c4-4ecb-c200-c03bda7f4954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_accuracy 0.9187527448397014\n",
            "validation_accuracy 0.8695652173913043\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def get_classifier_accuracy(model, X, y):\n",
        "  X_train, X_small, y_train, y_small = train_test_split(X, y,test_size=0.01, random_state=956)\n",
        "  model.fit(X_train,y_train)\n",
        "  y_pred=model.predict(X_small)\n",
        "  validation_accuracy = np.mean(y_pred == y_small)\n",
        "  y_train_pred=model.predict(X_train)\n",
        "  train_accuracy=np.mean(y_train_pred == y_train)\n",
        "  return train_accuracy,validation_accuracy\n",
        "\n",
        "\n",
        " \n",
        "  \n",
        "X, y = df.iloc[:,0:49],df.iloc[:,57]\n",
        "\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "\n",
        "train_accuracy, validation_accuracy = get_classifier_accuracy(model, X,y)\n",
        "\n",
        "print(\"train_accuracy\",train_accuracy)\n",
        "\n",
        "print(\"validation_accuracy\",validation_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1b2814",
      "metadata": {
        "id": "dc1b2814"
      },
      "source": [
        "### 2.3 Train and evaluate models (5 marks)\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "4. Call your accuracy function `get_classifier_accuracy()` using \n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`\n",
        "5. Add the data size, training and validation accuracy for each call to the `results` DataFrame\n",
        "6. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "68331fe9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68331fe9",
        "outputId": "e18d5590-928b-47ed-eb1e-a0fe1a0c6098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Data size  Training accuracy  Validation accuracy\n",
            "0     4600.0           0.916776             0.891304\n",
            "1     4600.0           0.635266             0.673913\n",
            "2       46.0           0.933333             0.673913\n"
          ]
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def get_classifier_accuracy(model, X, y):\n",
        "  X_train, X_small, y_train, y_small = train_test_split(X, y,test_size=0.01, random_state=956)\n",
        "  model.fit(X,y)\n",
        "  y_pred=model.predict(X_small)\n",
        "  validation_accuracy=np.mean(y_pred == y_small)\n",
        "  y_train_pred=model.predict(X_train)\n",
        "  train_accuracy=np.mean(y_train_pred == y_train)\n",
        "  return train_accuracy,validation_accuracy\n",
        "\n",
        "results = pd.DataFrame(columns=['Data size', 'Training accuracy', 'Validation accuracy'])\n",
        " \n",
        "  \n",
        "X, y = df.iloc[:,0:49],df.iloc[:,57]\n",
        "\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "data_size=X.shape[0]\n",
        "\n",
        "train_accuracy, val_accuracy = get_classifier_accuracy(model, X,y)\n",
        "\n",
        "\n",
        "results = results.append({'Data size': data_size,\n",
        "                          'Training accuracy': train_accuracy,\n",
        "                          'Validation accuracy': val_accuracy}, ignore_index=True)\n",
        "\n",
        "x_sample=X.iloc[:, :3]\n",
        "\n",
        "data_size=x_sample.shape[0]\n",
        "\n",
        "train_accuracy, val_accuracy = get_classifier_accuracy(model,x_sample, y)\n",
        "\n",
        "\n",
        "results = results.append({'Data size': data_size,\n",
        "                          'Training accuracy': train_accuracy,\n",
        "                          'Validation accuracy': val_accuracy}, ignore_index=True)\n",
        "\n",
        "\n",
        "X_train, X_small, y_train, y_small = train_test_split(X, y,test_size=0.01, random_state=956)\n",
        "\n",
        "data_size=X_small.shape[0]\n",
        "train_accuracy,validation_accuracy = get_classifier_accuracy(model,X_small,y_small)\n",
        "\n",
        "results = results.append({'Data size': data_size,\n",
        "                          'Training accuracy': train_accuracy,\n",
        "                          'Validation accuracy': val_accuracy}, ignore_index=True)\n",
        "\n",
        "   \n",
        "print(results)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7b8a83f",
      "metadata": {
        "id": "a7b8a83f"
      },
      "source": [
        "### 2.4 Questions (3 marks)\n",
        "1. What is the validation accuracy using all data? What is the difference between training and validation accuracy?\n",
        "1. How does the validation accuracy and difference between training and validation change when only two columns are used? Provide values.\n",
        "1. How does the validation accuracy and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n",
        "1) When a model's predictions on a validation dataset are compared to the actual labels in that dataset, the accuracy of the model's predictions is said to be the validation accuracy utilising all data.\n",
        "\n",
        "The training accuracy of a model refers to its accuracy on the training dataset that it saw throughout the training phase, while the validation accuracy of a model refers to its performance on a validation dataset that is not viewed during training.\n",
        "\n",
        "\n",
        "2) Depending on the importance of the columns to the target variable and the complexity of the model, using merely two columns in a dataset may have an impact on the validation accuracy and the difference between training and validation accuracy.\n",
        "\n",
        "Even if the two columns include very essential data, the model might still be able to achieve good validation accuracy with just those two columns.\n",
        "\n",
        "Data volume 460.0 Training effectiveness 0.635266 Validation precision is 0.673913.\n",
        "\n",
        "3) Since fewer data are available for the model's training and verification, it may be less able to make accurate predictions if only 1% of the rows are used.\n",
        "\n",
        "The model will be trained on a skewed sample and will perform poorly on the validation data if the 1% of rows selected are not representative of the entire dataset.\n",
        "\n",
        "Data volume 460.0 Training precision is 0.916776 Validation precision is 0.891304."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8d8810",
      "metadata": {
        "id": "4d8d8810"
      },
      "source": [
        "## 3. Regression (13 marks total)\n",
        "\n",
        "Using energy efficiency dataset - regression  \n",
        "http://archive.ics.uci.edu/ml/datasets/Energy+efficiency\n",
        "\n",
        "The goal is to investigate `LinearRegression()` and the effects of reducing the number of features and number of samples on regression performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c160bc",
      "metadata": {
        "id": "03c160bc"
      },
      "source": [
        "### 3.1 Load data (2 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "655c4a7d",
      "metadata": {
        "id": "655c4a7d"
      },
      "source": [
        "In the previous example, we downloaded the dataset from the UCI repository and read in the data using pandas\n",
        "\n",
        "Using sci-kit learn, you can access multiple datasets from UCI using the yellowbrick function (https://www.scikit-yb.org/en/latest/index.html)\n",
        "\n",
        "To install yellowbrick, use: `pip install yellowbrick`\n",
        "\n",
        "To access the energy efficiency dataset, visit: https://www.scikit-yb.org/en/latest/api/datasets/energy.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412e6c4d",
      "metadata": {
        "id": "412e6c4d"
      },
      "source": [
        "Using the yellowbrick function `load_energy()`, load the energy dataset into feature matrix `X` and target vector `y`\n",
        "\n",
        "Print dimensions and type of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yellowbrick"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr9IWUI23UdR",
        "outputId": "bb5af647-3fff-4566-ccd3-3bd7db5bf2ac"
      },
      "id": "zr9IWUI23UdR",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yellowbrick in /usr/local/lib/python3.8/dist-packages (1.5)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (0.11.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (1.21.6)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from yellowbrick) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5bf69314",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bf69314",
        "outputId": "d91c8e2e-e5df-4cc1-babf-fdd871b87e99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE (1 mark)\n",
        "\n",
        "from yellowbrick.datasets import load_energy\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "df2 = pd.read_excel('ENB2012_data.xlsx')\n",
        "df2.columns=[\"relative compactness\",\"surface area\",\"wall area\",\"roof area\",\"overall height\",\"orientation\",\"glazing area\",\"glazing area distribution\",\"heating load\", \"cooling load\"]\n",
        "\n",
        "features = [\n",
        "   \"relative compactness\",\n",
        "   \"surface area\",\n",
        "   \"wall area\",\n",
        "   \"roof area\",\n",
        "   \"overall height\",\n",
        "   \"orientation\",\n",
        "   \"glazing area\",\n",
        "   \"glazing area distribution\"\n",
        "]\n",
        "target = [\"heating load\", \"cooling load\"]\n",
        "df2 = load_energy(return_dataset=True).to_dataframe()\n",
        "X, y = df2[features], df2[target]\n",
        "\n",
        "X.shape\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e55a9601",
      "metadata": {
        "id": "e55a9601"
      },
      "source": [
        "Using the sklearn function `train_test_split()` prepare an additional feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`\n",
        "\n",
        "Print dimensions and type of `X_small` and `y_small`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5b39f9f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b39f9f0",
        "outputId": "54f2a487-4193-4f3f-ae52-4a9222c7202e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8)\n",
            "relative compactness         float64\n",
            "surface area                 float64\n",
            "wall area                    float64\n",
            "roof area                    float64\n",
            "overall height               float64\n",
            "orientation                    int64\n",
            "glazing area                 float64\n",
            "glazing area distribution      int64\n",
            "dtype: object\n",
            "______________________________\n",
            "(8, 2)\n",
            "heating load    float64\n",
            "cooling load    float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE (1 mark)\n",
        "\n",
        "X_train, X_small, y_train, y_small = train_test_split(X, y, test_size=0.01,random_state=174)\n",
        "\n",
        "print(X_small.shape)\n",
        "print(X_small.dtypes)\n",
        "print('______________________________')\n",
        "print(y_small.shape)\n",
        "\n",
        "print(y_small.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9243df31",
      "metadata": {
        "id": "9243df31"
      },
      "source": [
        "### 3.2 Implement accuracy function (3 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f7364b30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7364b30",
        "outputId": "0a6a2e4d-517b-43ba-9123-8f77487a23b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_mse 9.429085570183652\n",
            "validation_mse 5.897659522510363\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "def get_regressor_mse(model, X, y):\n",
        "\n",
        "   X_train, X_small, y_train, y_small = train_test_split(X, y,test_size=0.01, random_state=174)\n",
        "   model.fit(X_train,y_train)\n",
        "   y_pred=model.predict(X_small)\n",
        "   valid_mse = mean_squared_error(y_small,y_pred)\n",
        "   y_train_pred=model.predict(X_train)\n",
        "   train_mse=mean_squared_error(y_train,y_train_pred)\n",
        "   return train_mse,valid_mse\n",
        "\n",
        "X, y = df2[features], df2[target]\n",
        "model=LinearRegression()\n",
        "train_mse, valid_mse = get_regressor_mse(model, X,y)\n",
        "\n",
        "print(\"train_mse\",train_mse)\n",
        "print(\"validation_mse\",valid_mse)\n",
        "\n",
        "\n",
        "    #TODO: IMPLEMENT FUNCTION BODY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2cae8a",
      "metadata": {
        "id": "db2cae8a"
      },
      "source": [
        "### 3.3 Train and evaluate models (5 marks)\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LinearRegression()`.\n",
        "3. Create a pandas DataFrame `results` with columns: Data size, training MSE, validation MSE\n",
        "4. Call your accuracy function `get_regressor_mse()` using \n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`\n",
        "5. Add the data size, training and validation MSE for each call to the `results` DataFrame\n",
        "6. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c19ac5bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c19ac5bd",
        "outputId": "e8d5223d-2ef6-493f-8d2a-e2472369b25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Data size  Training MSE  Validation MSE\n",
            "0      768.0      0.933333        0.673913\n",
            "1      768.0      0.933333        0.673913\n",
            "2        8.0      0.933333        0.673913\n"
          ]
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def get_regressor_mse(model, X, y):\n",
        "\n",
        "   X_train, X_small, y_train, y_small = train_test_split(X, y,test_size=0.01, random_state=174)\n",
        "   model.fit(X_train,y_train)\n",
        "   y_pred=model.predict(X_small)\n",
        "   valid_mse = mean_squared_error(y_small,y_pred)\n",
        "   y_train_pred=model.predict(X_train)\n",
        "   train_mse=mean_squared_error(y_train,y_train_pred)\n",
        "   return train_mse,valid_mse\n",
        "\n",
        "results = pd.DataFrame(columns=['Data size', 'Training MSE', 'Validation MSE'])\n",
        " \n",
        "  \n",
        "X, y = df2[features], df2[target]\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "data_size=X.shape[0]\n",
        "\n",
        "train_mse, valid_mse = get_regressor_mse(model, X,y)\n",
        "\n",
        "results = results.append({'Data size': data_size,\n",
        "                          'Training MSE': train_accuracy,\n",
        "                          'Validation MSE': val_accuracy}, ignore_index=True)\n",
        "\n",
        "x_sample=X.iloc[:, :3]\n",
        "\n",
        "data_size=x_sample.shape[0]\n",
        "\n",
        "train_mse, valid_mse = get_regressor_mse(model, x_sample,y)\n",
        "\n",
        "\n",
        "results = results.append({'Data size': data_size,\n",
        "                          'Training MSE': train_accuracy,\n",
        "                          'Validation MSE': val_accuracy}, ignore_index=True)\n",
        "\n",
        "data_size=X_small.shape[0]\n",
        "train_mse, valid_mse = get_regressor_mse(model, X_small,y_small)\n",
        "\n",
        "results = results.append({'Data size': data_size,\n",
        "                          'Training MSE': train_accuracy,\n",
        "                          'Validation MSE': val_accuracy}, ignore_index=True)\n",
        "\n",
        "\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7e995e",
      "metadata": {
        "id": "ab7e995e"
      },
      "source": [
        "### 3.4 Questions (3 marks)\n",
        "1. What is the validation MSE using all data? What is the difference between training and validation MSE?\n",
        "1. How does the validation MSE and difference between training and validation change when only two columns are used? Provide values.\n",
        "1. How does the validation MSE and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n",
        "1) The average squared difference between the model's predicted values and the actual values in the validation dataset is referred to as the validation Mean Squared Error (MSE) using all data. The MSE calculates how inaccurately the model's forecasts are, on average.\n",
        "\n",
        "The average squared difference between the model's predicted values and the actual values in the training dataset that were noticed during training is known as the training MSE. The validation MSE, which the model did not experience during training, is the average squared difference between the predicted values and the actual values in the validation dataset.\n",
        "\n",
        "2) The model might only have a low validation MSE if the two columns include highly pertinent data. But if the two columns don't have enough data to accurately forecast the goal variable, the model may provide a high validation MSE.\n",
        "\n",
        "3) The amount of data available for the model's training and verification decreases when only 1% of the rows are used, which may have an impact on the model's ability to make accurate predictions.\n",
        "\n",
        "The model will be trained on a skewed sample and will perform poorly on the validation data if the 1% of rows selected are not representative of the entire dataset.\n",
        "\n",
        "Validation mse 5.897659522510363, Train mse 9.429085570183652"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29cc84c9",
      "metadata": {
        "id": "29cc84c9"
      },
      "source": [
        "## 4. Observations/Interpretation (3 marks)\n",
        "\n",
        "Describe any patterns you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "*ADD YOUR FINDINGS HERE*\n",
        "\n",
        "Using reduced feature data and its effects\n",
        "\n",
        "If we restrict the feature space from which the model may learn, this may affect how well the predictions on validation data turn out.\n",
        "\n",
        "The model may overfit the training data if the chosen data is highly associated with the target variable and perform badly on the validation data.\n",
        "\n",
        "Underfitting: The model underfits the training data and performs badly on both the training and validation data if the chosen data is insufficient to predict the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a16b7bbd",
      "metadata": {
        "id": "a16b7bbd"
      },
      "source": [
        "## 5. Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "*ADD YOUR THOUGHTS HERE*\n",
        "\n",
        "Class notes are very helpful in completing this assignment because it provides a deeper understanding of logistic and linear regression models. \n",
        "\n",
        "I learned more practical information about how to train and evaluate the model, how smaller data affect training and validation accuracy, and how to split a dataset into a feature and a target vector how to determine the model's correctness how to determine MSE which models suit the various data sets the best."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efe13d69",
      "metadata": {
        "id": "efe13d69"
      },
      "source": [
        "# Assignment 4: Neural Networks (30 marks)\n",
        "### Due date: March 31 at 11:59pm\n",
        "*Author: Hetalben Virani*\n",
        "\n",
        "For this assignment, you will be practicing using scikit-learn and TensorFlow to implement basic neural networks (MLP). You can use the given dataset below, or you can use the dataset you have selected for your project.\n",
        "\n",
        "**Note: If you use the dataset from your project - this assignment is meant to be completed individually. You may work with your group members to complete this assignment, but the work you submit must be your own. Submitting identical assignments is a form of academic misconduct**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "69e955bf",
      "metadata": {
        "id": "69e955bf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f155621",
      "metadata": {
        "id": "0f155621"
      },
      "source": [
        "## Part 1: Load your dataset (1 mark)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb31fa4e",
      "metadata": {
        "id": "eb31fa4e"
      },
      "source": [
        "As stated above, you can use the dataset from your project. If you want to practice neural networks with a different dataset, you can use the energy dataset from Yellowbrick (https://www.scikit-yb.org/en/latest/api/datasets/energy.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yellowbrick"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNp2fIzBsmEN",
        "outputId": "17dc27de-970c-43e6-8250-c06e4e90b62c"
      },
      "id": "jNp2fIzBsmEN",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yellowbrick in /usr/local/lib/python3.9/dist-packages (1.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.2.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (0.11.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from yellowbrick) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (8.4.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a115228d",
      "metadata": {
        "id": "a115228d"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "\n",
        "from yellowbrick.datasets import load_energy\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_excel('ENB2012_data1.xlsx')\n",
        "df.columns=[\"relative compactness\",\"surface area\",\"wall area\",\"roof area\",\"overall height\",\"orientation\",\"glazing area\",\"glazing area distribution\",\"heating load\", \"cooling load\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f99a3675",
      "metadata": {
        "id": "f99a3675"
      },
      "source": [
        "## Part 2: Process your dataset (5 marks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "S0cHlW5wEgCX"
      },
      "id": "S0cHlW5wEgCX",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "2d817a92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d817a92",
        "outputId": "f909e91e-d2a4-40c2-9778-63999f1e9487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relative compactness         0\n",
            "surface area                 0\n",
            "wall area                    0\n",
            "roof area                    0\n",
            "overall height               0\n",
            "orientation                  0\n",
            "glazing area                 0\n",
            "glazing area distribution    0\n",
            "heating load                 0\n",
            "cooling load                 0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check if there are any missing values - if yes, decide how to fill them\n",
        "\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ac664776",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac664776",
        "outputId": "a119d173-ce24-4142-bc8c-269ff8208383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     relative compactness  surface area  wall area  roof area  overall height  \\\n",
            "min                  0.62         514.5      245.0     110.25             3.5   \n",
            "max                  0.98         808.5      416.5     220.50             7.0   \n",
            "\n",
            "     orientation  glazing area  glazing area distribution  heating load  \\\n",
            "min          2.0           0.0                        0.0          6.01   \n",
            "max          5.0           0.4                        5.0         43.10   \n",
            "\n",
            "     cooling load  \n",
            "min         10.90  \n",
            "max         48.03  \n"
          ]
        }
      ],
      "source": [
        "# Check the range of each feature - do you need to scale your data?\n",
        "range=df.describe().loc[['min','max']]\n",
        "print(range)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "35723631",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35723631",
        "outputId": "be5f470a-5f0d-4490-e989-244fb8806db0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Split your data into training and testing datasets (select random_state=0 and use default test_size)\n",
        "\n",
        "features = [\n",
        "   \"relative compactness\",\n",
        "   \"surface area\",\n",
        "   \"wall area\",\n",
        "   \"roof area\",\n",
        "   \"overall height\",\n",
        "   \"orientation\",\n",
        "   \"glazing area\",\n",
        "   \"glazing area distribution\"\n",
        "]\n",
        "target = [\"heating load\", \"cooling load\"]\n",
        "\n",
        "X, y = df[features], df[target]\n",
        "\n",
        "X.shape\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3jq7EazIFISB"
      },
      "id": "3jq7EazIFISB",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "7b91d54b",
      "metadata": {
        "id": "7b91d54b"
      },
      "outputs": [],
      "source": [
        "# Implement scaling and/or encoding here if needed (2 marks for preprocessing properly or justifying why it isn't needed)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling is not really necessary for energy efficiency databases because all the features are numerical and measured on similar scales.\n",
        "\n",
        "Only the columns \"orientation\" and \"glazing area distribution\" include categorial values; however, as these values are already numerically encoded, encoding is not necessary."
      ],
      "metadata": {
        "id": "-diU7FrpzOIN"
      },
      "id": "-diU7FrpzOIN"
    },
    {
      "cell_type": "markdown",
      "id": "e00a4613",
      "metadata": {
        "id": "e00a4613"
      },
      "source": [
        "## Part 4: Implement MLP using scikit-learn (5 marks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n"
      ],
      "metadata": {
        "id": "LuFkg0md1Oxi"
      },
      "id": "LuFkg0md1Oxi",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "1e43c1ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "1e43c1ed",
        "outputId": "6c5d44bf-a0e4-4a57-efdf-db82a2ad075d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(alpha=0.001, max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(alpha=0.001, max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=0.001, max_iter=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Test using default parameters (set max_iter=500 - for this assignment, don't worry about reaching convergence)\n",
        "\n",
        "\n",
        "mlp1 = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam',alpha=0.001, max_iter=500, random_state=None)\n",
        "mlp1.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "5b0e1272",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "5b0e1272",
        "outputId": "23e256fb-2849-4460-ff8c-a01df2d330c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Test using two hidden layers with 100 nodes each\n",
        "\n",
        "mlp2 = MLPRegressor(hidden_layer_sizes=(100,100), activation='relu', solver='adam', max_iter=500, random_state=None)\n",
        "mlp2.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5909134e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "5909134e",
        "outputId": "e50194cd-78f6-415f-b3da-fc4cfc14f2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Test using three hidden layers with 100 nodes each\n",
        "mlp3 = MLPRegressor(hidden_layer_sizes=(100,100,100), activation='relu', solver='adam', max_iter=500, random_state=None)\n",
        "mlp3.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c466dd60",
      "metadata": {
        "id": "c466dd60"
      },
      "source": [
        "## Part 5: Implement MLP using TensorFlow (7 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "00362479",
      "metadata": {
        "id": "00362479"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f525ba9",
      "metadata": {
        "id": "5f525ba9"
      },
      "source": [
        "Instead of scaling the data using a scikit-learn scaler, you can scale the data using a normalization layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "6e61cbff",
      "metadata": {
        "id": "6e61cbff"
      },
      "outputs": [],
      "source": [
        "# Define normalization layer\n",
        "normalizer = preprocessing.Normalization()\n",
        "normalizer.adapt(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A normalization layer normalizes the input data so that the mean and standard deviation are close to 0 and 1, respectively. This can help to increase neural network performance by making the optimisation process more reliable and efficient. "
      ],
      "metadata": {
        "id": "Y8byPwXQ7fy8"
      },
      "id": "Y8byPwXQ7fy8"
    },
    {
      "cell_type": "markdown",
      "id": "8f156626",
      "metadata": {
        "id": "8f156626"
      },
      "source": [
        "Using `keras.Sequential`, implement an MLP with the same hidden layer setups as above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c85ee327",
      "metadata": {
        "id": "c85ee327"
      },
      "outputs": [],
      "source": [
        "# One hidden layer with 100 nodes and the relu activation function\n",
        "# Compile the model with loss='mean_absolute_error' and optimizer=tf.keras.optimizers.Adam(0.001)\n",
        "# Fit the model using validation_split=0.2, verbose=0 and epochs=100\n",
        "\n",
        "\n",
        "modeltf1= tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "optim=tf.keras.optimizers.Adam(0.001)\n",
        "\n",
        "modeltf1.compile(optimizer=optim,loss='mean_absolute_error')\n",
        "\n",
        "history=modeltf1.fit(X_train, y_train,validation_split=0.2, epochs=100,verbose=0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ecb3d7fa",
      "metadata": {
        "id": "ecb3d7fa"
      },
      "outputs": [],
      "source": [
        "# Repeat with two hidden layers with 100 nodes each and the relu activation function\n",
        "\n",
        "\n",
        "modeltf2 = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "optim=tf.keras.optimizers.Adam(0.001)\n",
        "\n",
        "modeltf2.compile(optimizer=optim,loss='mean_absolute_error')\n",
        "\n",
        "history=modeltf2.fit(X_train, y_train,validation_split=0.2, epochs=100,verbose=0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "3713a9fe",
      "metadata": {
        "id": "3713a9fe"
      },
      "outputs": [],
      "source": [
        "# Repeat with three hidden layers with 100 nodes each and the relu activation function\n",
        "\n",
        "modeltf3 = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "optim=tf.keras.optimizers.Adam(0.001)\n",
        "\n",
        "modeltf3.compile(optimizer=optim,loss='mean_absolute_error')\n",
        "\n",
        "history=modeltf3.fit(X_train, y_train,validation_split=0.2, epochs=100,verbose=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19fc1f12",
      "metadata": {
        "id": "19fc1f12"
      },
      "source": [
        "## Part 6: Compare the accuracy of both methods (7 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d7700c5",
      "metadata": {
        "id": "8d7700c5"
      },
      "source": [
        "For this part, calculate the mean absolute error for each model and print in a table using pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "a270fc6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a270fc6e",
        "outputId": "004967bb-562d-4c43-c365-d61437e226f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_absolute_error 1.971054823002238\n",
            "mean_absolute_error 1.2197642210729747\n",
            "mean_absolute_error 0.6974092523020543\n"
          ]
        }
      ],
      "source": [
        "# Calculate the MAE for the three scikit-learn tests\n",
        "\n",
        "\n",
        "y_pred = mlp1.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mean_absolute_error\",mae)\n",
        "\n",
        "y_pred = mlp2.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mean_absolute_error\",mae)\n",
        "\n",
        "y_pred = mlp3.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"mean_absolute_error\",mae)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "6d0a9c86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d0a9c86",
        "outputId": "05ff9c97-64af-43f3-9d10-4052456fa4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_absolute_error 1.950364112854004\n",
            "mean_absolute_error 1.7963893413543701\n",
            "mean_absolute_error 1.710618257522583\n"
          ]
        }
      ],
      "source": [
        "# Calculate the MAE for the three tensor flow tests\n",
        "\n",
        "mae = modeltf1.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"mean_absolute_error\",mae)\n",
        "\n",
        "mae = modeltf2.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"mean_absolute_error\",mae)\n",
        "\n",
        "mae = modeltf3.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"mean_absolute_error\",mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "83c978ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83c978ef",
        "outputId": "bcfbc7e5-cf44-4636-e101-63ee346878d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Model  Model1  Model2  Model3\n",
            "0  MAE_scikit-learn  2.0132  1.2209  0.7827\n",
            "1   MAE_tensor-flow  1.9773  1.7151  1.6292\n"
          ]
        }
      ],
      "source": [
        "# Print the results\n",
        "\n",
        "results = {\n",
        "    'Model': ['MAE_scikit-learn', 'MAE_tensor-flow'],\n",
        "    'Model1': [2.0132, 1.9773],\n",
        "    'Model2': [1.2209,1.7151],\n",
        "    'Model3': [0.7827, 1.6292],\n",
        "    \n",
        "}\n",
        "\n",
        "result1 = pd.DataFrame(results)\n",
        "\n",
        "\n",
        "print(result1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71558bca",
      "metadata": {
        "id": "71558bca"
      },
      "source": [
        "## Part 7: Questions (5 marks total)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fbd3194",
      "metadata": {
        "id": "5fbd3194"
      },
      "source": [
        "### Question 1: Which model produced the least amount of error? (1 mark)\n",
        "\n",
        "When we implemeneted the MLP using scikit-learn with three hidden layers with 100 nodes each and the relu activation function  then we got least mean_absolute_error \n",
        "\n",
        "              Model  Model1  Model2  Model3\n",
        "0  MAE_scikit-learn  2.0132  1.2209  0.7827\n",
        "1   MAE_tensor-flow  1.9773  1.7151  1.6292"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c883ecd7",
      "metadata": {
        "id": "c883ecd7"
      },
      "source": [
        "### Question 2: Why are the numbers different between the scikit-learn and TensorFlow methods when we used the same number of hidden layers and hidden units per layer? (2 marks)\n",
        "\n",
        "There are a few reasons why the MAEs differ even when we use the same number of hidden layers and neurons per layer.\n",
        "\n",
        "Different methods and optimisation strategies are used by the scikit-learn and tensorflow packages, respectively.\n",
        "\n",
        "\n",
        "For example: learning rate, regularisation strength, etc. can have a considerable impact on the performance of the model. Hyperparameter adjustment is also very important.\n",
        "\n",
        "\n",
        "We must make sure that the hyperparameter values for both libraries are identical.\n",
        "\n",
        "\n",
        "The MAE'S are also impacted by the preprocessing processes. For instance, if the data is scaled differently in scikit-learn and TensorFlow, this can produce different results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85be7c97",
      "metadata": {
        "id": "85be7c97"
      },
      "source": [
        "### Question 3: Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challenging, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "This assignment provides you with a fundamental understanding of how to create MLP using TensorFlow and Scikit-Learn.\n",
        "\n",
        "After doing this assignment I came across how the model performance changes with the change in layers and nodes in MLP by computing and comparing the MAE for each model while altering the hidden layers and nodes.\n",
        "\n",
        "Understanding the hyperparameter parameters for tensorflow models felt a little difficult as the concept was the totally new for me so that I did clear basic fundamentals.\n",
        "\n",
        "Further lectures, notes, and examples on how to design MLP using scikit-learn and tensor flow, as well as more lectures on the in-depth ideas of these libraries, in my opinion, would be more beneficial."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}